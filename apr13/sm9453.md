---
title: "Programming Models: Serverless"
author: Safwan Mahmood  <sm9453@nyu.edu>
---
# Introduction
A brief look into Serverless Programming Models:
* Kappa: A Programming Framework for Serverless Computing.
* NumPyWren: Serverless Linear Algebra.
* Serverless IFC: Secure Serverless Computing using Dynamic Information Flow Control.

# Kappa: A Programming Framework for Serverless Computing

## Introduction

Serverless computing is a new cloud paradigm where, instead of provisioning virtual machines (VMs), tenants register event handlers (e.g., Python functions) with the platform. When an event occurs, the platform invokes the handler on a lambda function, a short-lived, stateless execution environment. A lambda function can execute for a bounded duration before being terminated.

Serverless computing benefits both cloud tenants and providers. Tenants no longer need to provision or scale their VMs, and enjoy greater elasticity from fast lambda boot times (100s of ms on AWS). Providers can periodically terminate jobs running on lambda functions (and place the next invocation elsewhere if desired), improving datacenter utilization.

## Motivation

Developing general-purpose parallel applications on today’s serverless platforms remains difficult due to two main challenges: 
1. Programmers must manually partition their computation to fit within the lambda function time limit. They usually assume that
each task can run for an arbitrary duration until it completes. Lambda functions, however, are time-bounded and thus might not complete a task of arbitrary length.  
2. Programmers have no concurrency or synchronization methologies at their disposal, and so must either implement such methologies or restrict themselves to use share-nothing parallelism, or stay clear of parallel lambdas all together.

Kappa aims to make serverless development as close to ordinary parallel programming as possible. A programmer can write ordinary
Python code using a familiar concurrency API (e.g., tasks and futures), and Kappa runs the code on an unmodified serverless platform like AWS Lambda using parallel lambda functions.

Kappa requires no changes to the platform, thus allowing general applications to run on existing serverless offerings, which is the main contribution of this work.

## Approaches

**Kappa Design**
Kappa executes parallel code of arbitrary duration using short-lived lambda functions. 
Here, a **task** represents a logical thread of execution running in its own memory space, and can physically runs on one or more lambda functions. Tasks are allowed to span multiple lambda functions by periodically checkpointing them.
Kappa enables concurrent processing by allowing each task to spawn other tasks which execute in parallel, and by providing inter-task communication mechanisms that allow tasks to communicate and coordinate with each other.

Kappa has three components: 
1. Kappa Coordinator : responsible for launching and resuming tasks and for implementing Kappa's concurrency primitives.
2. Kappa Compiler : responsible for generating code required for checkpointing.
3. Kappa library : used by tasks for checkpointing, concurrent processing, and synchronization.

**Flow**


![Kappa](images/kappa-flow.png)


1. Programmer writes code similar to what runs on a traditional platform, with minor modifications required by Kappa.
2. The compiler transforms this code into a form suitable for use by Kappa.
3. The program is packaged with the Kappa library and launched by the coordinator, which starts by running a designated “main” task.

**Coordinator**
1. The Kappa coordinator is responsible for scheduling tasks on lambda functions, implementing synchronization and cross-task communication, tracking task metadata (including checkpoints), and providing fault tolerance.
2. The coordinator tracks the latest checkpoint of each task. A task writes checkpoint content directly to storage (e.g., S3 or Redis), and the coordinator maintains only checkpoint locations.
3. Tasks communicate with the coordinator through the remote procedure calls (RPCs) like below:


![Kappa](images/kappa-coord.png)


4. Coordinator RPCs are synchronous by default. Also supports asynchronous RPCs, which return as soon
as the checkpoint has been serialized locally. A background process then persists the checkpoint to storage and contacts the coordinator. 
(**Note:** Because the actual RPC logic is executed at the coordinator, no processing occurs until the coordinator has been contacted. As a result, in case the lambda is killed before the coordinator is contacted, it is safe to restore the task to its previous checkpoint (before the RPC is issued).

5. For RPCs which are **blocking** (e.g., wait), a task blocks by first busy-waiting for a configurable period (1 s by default), and then quitting the lambda function. In the latter case, the task is resumed by the coordinator once unblocked. This provides better resource efficiency than pure busy waiting and better performance than immediately blocking.

6. For **fault tolerance** of the coordinator itself, Kappa provides the option to continuously replicate coordinator state to a backing store (currently, a Redis cluster using primarybackup replication). With this option enabled, every time the
coordinator processes an RPC or a lambda function timeout, it sends a state update to the backing store and waits for it to be persisted. The coordinator can reconstruct its previous state from the store and resume the workload upon failure.  
Further, the overhead of backing store can be further reduced by having the coordinator send batch updates periodically.


**Checkpointing**

Kappa uses checkpoints to tolerate lambda function timeouts and to prevent RPC duplication. 
Checkpoints in Kappa are implemented using **continuations**, a language-level mechanism executed in user mode.

A **continuation** can be thought of as a closure (i.e., a function with some associated data) that captures program state and control flow information at some execution point. Calling the closure resumes execution from this point in the program.

Kappa takes a checkpoint by generating a continuation and serializing it to storage, and restores from a checkpoint by deserializing and invoking a previously stored continuation. Kappa's continuations implementation is specialized to Python. 

**Generating continuation functions:** To reduce runtime overhead, Kappa generates continuation code for each pause point at compile time. Pause points can be inserted manually (by invoking an RPC) or automatically by the compiler using a simple heuristic—before each function call, checkpoint if five seconds has elapsed since the previous checkpoint. 

**Runtime behavior** At every pause point, our compiler inserts an exception handler that creates a continuation upon catching an exception. To make an RPC, the Kappa library records details of the call and raises a special exception, triggering
the exception handler at every level of the call stack. Each handler appends a new continuation and re-raises the exception. Finally, the top-most handler, part of the Kappa library, serializes and persists the list of continuations.


**Concurrency API**

Kappa provides mechanisms for launching and synchronizing parallel tasks, making it easier to exploit the resource elasticity offered by serverless platforms.
1. **Spawn:** The spawn RPC launches a new task to execute a function call in parallel and returns a future for the result.
2. **FIFO queues:** Kappa tasks can communicate using multiproducer multi-consumer FIFO queues.

**External Services**
A Kappa task can call services external to the platform (e.g.,
a REST API for computer vision). Interactions with external
services pose two fault tolerance challenges: Kappa must
ensure that (1) external calls with side effects be issued only
once even when lambdas time out;8
and (2) calls that last
longer than the lambda time limit make progress.

Kappa solves both challenges in an extensible manner using spawn: the programmer wraps a stateful external call in
a child task, spawns it on the coordinator (§ 3.3), and waits
for it to finish.9 The RPC mechanism (§ 3.1) ensures that the
spawn, and thus the external service call, is never duplicated
(assuming no coordinator failures). In case of a long-lasting
call, the wait would block, causing the parent task to terminate and restart when the child finishes



**Comparing Platforms**


![Kappa](images/kappa-flow.png)


To use most of the previous frameworks, the programmer must:
1. Partition the computation into small components, each of which must fit within the lambda functiontime limit and meet other framework-specific restrictions (e.g., to simplify fault tolerance)
2. Compose these components into a serverless application using a framework-specific format.

Kappa’s checkpointing mechanism can resume a task when a lambda function times out, freeing the programmer from having to manually partition their computation. 
Kappa’s high-level concurrency API lets programmers develop parallel serverless applications using a familiar programming model.


## Tradeoffs

Tasks may lose some progress and re-execute some code as a result of being restarted.

The Kappa compiler conservatively assumes every function call to be a transitive pause point and generates a continuation function for it. This strategy bloats the transformed code. (Although they found that the resulting code size is still negligible compared to the Kappa and third-party libraries)

The overhead of checkpointing could be higher for other languages, as the compiler wraps every function call in a
try/except block.

Kappa uses storage services for checkpoints and large queue elements, they currently support only using S3 and Redis for storage. 

Garbage collection (GC) is currently implemented only for Redis. ( For S3: Since S3 storage is cheap, they simply delete all S3 objects when a workload ends)

Python’s yield keyword which suspends a function and transfers control to its caller is not used as they are unaware of any
portable technique for serializing the suspended state.

Static pause points restricts where checkpoints can be generated and precludes deciding checkpoint locations at runtime.

Kappa can checkpoint only in code transformed by the its compiler and not in, example a Python C extension like numpy.

The Kappa compiler does not ensure at compile time that every variable captured by a checkpoint is serializable, showing lack of static checking.

The programmer must Insert checkpoint() calls at appropriate points in the program, mark calls that have externally visible side-effects along with ensuring that such calls are executed only once.  They have to use Kappa’s concurrency primitives instead of primitives such as Python threads.


## Open Questions and Future Work

Kappa has unsupported Python features to the compiler’s continuation generation logic. These features include try/except, yield, async/await, nested function definitions, and global variables. These limitations are not fundamental but can be future work.

Kappa currently checkpoints if five seconds has elapsed since the previous checkpoint. Finding better methods is a future work.

Removing Restrictions like where in code the checkpoints can be generated and deciding checkpoint locations before runtime and coming up with dynamic continuation computation is an area to work on.

A future direction can be to implement static checking by leveraging Python type hints.

Adding the unimplemented GC features.


